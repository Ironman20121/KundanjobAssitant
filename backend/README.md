


git clone https://github.com/Ironman20121/KundanjobAssitant.git
cd jobAssistant/backend
pip install -r requirement.txt


install ollam  for custom os

ollam pull model name 



Model Name	Command to Install	Size	RAM Usage
Phi-3 (Microsoft)	ollama pull phi3	3.8B	~4GB
TinyLlama	ollama pull tinyllama	1.1B	~2GB
Gemma 2B (Google)	ollama pull gemma:2b	2B	~3GB
Llama3 8B (Quantized)	ollama pull llama3:8b	8B*	~6GB

model change can be done 85,216 line of optimized_resume_maker.py 

tried fixing ai chanlanges like explaination enhanced promp
for reducing time duration used  buffer instead diskstorage
using threading in list call but still it 

even after all this  dec from 8 min to 5 mins


I belive instead of this  latex templete from AI and genreate latex resune instead gnerate to python lib thay way even multple prmpts call will also reduce 
